<?xml version="1.0" encoding="UTF-8"?>
<!--
    ~
    ~ Copyright 2024 tosit.io
    ~
    ~ Licensed under the Apache License, Version 2.0 (the "License");
    ~ you may not use this file except in compliance with the License.
    ~ You may obtain a copy of the License at
    ~
    ~     http://www.apache.org/licenses/LICENSE-2.0
    ~
    ~ Unless required by applicable law or agreed to in writing, software
    ~ distributed under the License is distributed on an "AS IS" BASIS,
    ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    ~ See the License for the specific language governing permissions and
    ~ limitations under the License.
    ~
  -->
<!-- 
    OKDP spark docker images add-ons:
    * Manage compatibilty (transitive) dependency versions between Hadoop, spark and extensions.
    * Prevents mixing extensions (e.x.hadoop-aws) version with other hadoop artifacts from different versions.
    * Manage AWS SDK V2 and SDK V1 for S3 (breaking changes between SDK V1 and V2) versions.
    * See also: https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-project-maven.html
    * See also: https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/aws_sdk_upgrade.html
    * See also: https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/home.html
    * See also: https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup-project-maven.html
-->
<project xmlns="http://maven.apache.org/POM/4.0.0"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <name>OKDP Addons</name>
    <groupId>io.okdp</groupId>
    <artifactId>okdp-spark-docker-addons</artifactId>
    <version>${spark.version}</version>
    <packaging>pom</packaging>
    <description>
       OKDP extensions for spark docker images
    </description>
    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>
    <dependencies>
        <!-- *** Default OKDP Extensions *** -->
        <!-- okdp spark auth filter -->
        <dependency>
            <groupId>io.okdp</groupId>
            <artifactId>okdp-spark-auth-filter</artifactId>
            <version>1.1.0</version>
            <exclusions>
                <exclusion>
                    <groupId>*</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <!-- jmx prometheus agent -->
        <dependency>
            <groupId>io.prometheus.jmx</groupId>
            <artifactId>jmx_prometheus_javaagent</artifactId>
            <version>0.20.0</version>
            <exclusions>
                <exclusion>
                    <groupId>*</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <!-- minio/aws S3 requirement -->
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>${hadoop.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>*</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
    </dependencies>
    <profiles>
        <profile>
            <!-- minio/aws S3 
            The AWS bandle can take up 500MB, to be optimized later! -->
            <id>aws</id>
            <dependencies>
                <dependency>
                    <groupId>org.apache.hadoop</groupId>
                    <artifactId>hadoop-aws</artifactId>
                    <version>${hadoop.version}</version>
                </dependency>
                <!-- S3A Committers:
                https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/committers.md 
                -->
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-hadoop-cloud_${scala.version}</artifactId>
                    <version>${spark.version}</version>
                    <exclusions>
                        <exclusion>
                            <groupId>*</groupId>
                            <artifactId>*</artifactId>
                        </exclusion>
                    </exclusions>
                </dependency>
            </dependencies>
        </profile>
    </profiles>
</project>