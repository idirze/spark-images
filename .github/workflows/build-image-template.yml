
#
# Copyright 2024 tosit.io
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

name: Spark build single image template

on:
  workflow_call:
    inputs:
      image:
        description: The spark image name (ex. spark-base, spark, spark-py, spark-r, etc)
        required: true
        type: string
      spark_version:
        description: Spark version
        required: true
        type: string
      scala_version:
        description: Scala version
        required: true
        type: string
      java_version:
        description: Java version
        required: true
        type: string
      hadoop_version:
        description: Hadoop version
        required: true
        type: string
      python_version:
        description: Python version
        required: true
        type: string
      publish_to_registry:
        description: Wheter to push to the registry
        required: false
        type: string
        default: "false"
      registry:
        description: The container registry 
        required: false
        type: string
      ci_registry:
        description: "The registry used to push ci images"
        required: false
        type: string
        default: "ghcr.io"
      git_latest_release_tag:
        description: The latest remote release tag 
        required: false
        type: string
        default: ""
      runs-on:
        description: GitHub Actions Runner image
        required: true
        type: string

jobs:
  
  build-test-push:
    name: ${{ inputs.image }} (scala-${{ inputs.scala_version }}, java-${{ inputs.java_version }}, python-${{ inputs.python_version }})
    runs-on: ${{ inputs.runs-on }}
    steps:

      ### The publish and periodic rebuilds are based on the latest stable release tag
      - name: Checkout latest Github Release tag (${{ inputs.git_latest_release_tag }}) âš¡ï¸
        if: inputs.publish_to_registry == 'true'
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.git_latest_release_tag }}
      
      ### The CI is based on the main branch
      - name: Checkout Repo âš¡ï¸
        if: inputs.publish_to_registry == 'false'
        uses: actions/checkout@v4

      ### Common steps between CI and Publish
      - name: Free up disk space ğŸ“¦
        uses: ./.github/actions/free-disk-space

      - name: Set up QEMU and Docker Buildx ğŸ“¦
        uses: ./.github/actions/setup-buildx

      - name: Set up CI and Publish registries ğŸ“¦
        id: registry-repos
        run:  |
            echo "repo_owner=${GITHUB_REPOSITORY_OWNER@L}" >> $GITHUB_OUTPUT
            echo "ci_repo=${{ inputs.ci_registry }}/${GITHUB_REPOSITORY_OWNER@L}" >> $GITHUB_OUTPUT
            echo "publish_repo=${{ inputs.registry }}/${GITHUB_REPOSITORY_OWNER@L}" >> $GITHUB_OUTPUT
        shell: bash

      - name: Generate image tags ğŸ“¦
        id: image-tags
        uses: ./.github/actions/spark-image-tag
        with:
          image: ${{ inputs.image }}
          spark_version: ${{ inputs.spark_version}}
          scala_version: ${{ inputs.scala_version }}
          java_version: ${{ inputs.java_version }}
          python_version: ${{ inputs.python_version}}
          ci_repo: ${{ steps.registry-repos.outputs.ci_repo }}
          publish_repo: ${{ steps.registry-repos.outputs.publish_repo }}
          publish_to_registry: ${{ inputs.publish_to_registry }}
          git_tag_name: ${{ inputs.git_latest_release_tag }}

      - name: Login to the CI registry ğŸ”
        if: inputs.publish_to_registry == 'false' && !startsWith(inputs.spark_version, '2.')
        uses: docker/login-action@v3
        with:
          registry: ${{ inputs.ci_registry }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push to ci registry
        if: inputs.publish_to_registry == 'false' && !startsWith(inputs.spark_version, '2.')
        uses: docker/build-push-action@v5
        with:
          context: ${{ inputs.image }}
          platforms: linux/amd64,linux/arm64
          push: true
          build-args: |
            SPARK_VERSION=${{ inputs.spark_version}}
            SCALA_VERSION=${{ inputs.scala_version }}
            JAVA_VERSION=${{ inputs.java_version }}
            PYTHON_VERSION=${{ inputs.python_version }}
            HADOOP_VERSION=${{ inputs.hadoop_version }}
            BASE_IMAGE=${{ steps.image-tags.outputs.parent_image }}
          tags: |
            ${{ steps.registry-repos.outputs.ci_repo }}/${{ inputs.image }}:${{ steps.image-tags.outputs.latest_tag }}

      ### CI Steps
      # https://github.com/nektos/act/issues/678
      - name: Checkout integration tests tag v${{ inputs.spark_version }} (${{ inputs.spark_version}} > 3.0.0) âš¡ï¸
        if: inputs.publish_to_registry == 'false' && !startsWith(inputs.spark_version, '2.')
        id: git-checkout-tag
        run: |
            CHECKOUT_TAG_DIR="$(mktemp -d)/spark"
            git clone https://github.com/apache/spark.git ${CHECKOUT_TAG_DIR}
            cd ${CHECKOUT_TAG_DIR}
            git checkout v${{ inputs.spark_version }}
            echo "checkout_directory=${CHECKOUT_TAG_DIR}" >> $GITHUB_OUTPUT
        shell: bash

      - name: Prepare integration tests env (${{ inputs.spark_version}} > 3.0.0) ğŸ“¦
        if: inputs.publish_to_registry == 'false' && !startsWith(inputs.spark_version, '2.')
        uses: ./.github/actions/spark-tests-prepare
        with:
          spark_version: ${{ inputs.spark_version}}
          scala_version: ${{ inputs.scala_version }}
          java_version: ${{ inputs.java_version }}

      - name: Set up Kind integration tests cluster (${{ inputs.spark_version}} > 3.0.0) ğŸ“¦
        if: inputs.publish_to_registry == 'false' && !startsWith(inputs.spark_version, '2.')
        uses: ./.github/actions/setup-kind

      - name: Run integration tests (${{ inputs.spark_version}} > 3.0.0) âœ…
        if: inputs.publish_to_registry == 'false' && !startsWith(inputs.spark_version, '2.')
        uses: ./.github/actions/spark-tests-run
        with:
          ci-repo: ${{ steps.registry-repos.outputs.ci_repo }}
          image: ${{ inputs.image }}
          image-tag: ${{ steps.image-tags.outputs.latest_tag }}
          scala_version: ${{ inputs.scala_version }}
          git_checkout_tag_dir: ${{ steps.git-checkout-tag.outputs.checkout_directory }}

      ### Publish steps
      ### The publish and periodic rebuilds are based on the latest stable release tag
      - name: Login into publish registry ğŸ”
        if: inputs.publish_to_registry == 'true'
        uses: docker/login-action@v3
        with:
          registry: ${{ inputs.registry }}
          username: ${{ secrets.REGISTRY_USERNAME }}
          password: ${{ secrets.REGISTRY_ROBOT_TOKEN }}

      - name: Build and push to publish registry ğŸ“¤
        if: inputs.publish_to_registry == 'true'
        uses: docker/build-push-action@v5
        with:
          context: ${{ inputs.image }}
          platforms: linux/amd64,linux/arm64
          push: true
          build-args: |
            SPARK_VERSION=${{ inputs.spark_version}}
            SCALA_VERSION=${{ inputs.scala_version }}
            JAVA_VERSION=${{ inputs.java_version }}
            PYTHON_VERSION=${{ inputs.python_version }}
            HADOOP_VERSION=${{ inputs.hadoop_version }}
            BASE_IMAGE=${{ steps.image-tags.outputs.parent_image }}
          tags: ${{ steps.image-tags.outputs.publish_tags }}


